{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ivc.ischool.utexas.edu/VizWiz/data/Images/\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Annotations/train.json\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Annotations/test.json\n",
      "https://ivc.ischool.utexas.edu/VizWiz/data/Annotations/val.json\n"
     ]
    }
   ],
   "source": [
    "# 1. Classification Using Hand-Crafted Features\n",
    "# (a) \n",
    "# Load VizWiz dataset\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pprint import PrettyPrinter\n",
    "\n",
    "base_url = 'https://ivc.ischool.utexas.edu/VizWiz/data'\n",
    "img_dir = '%s/Images/' %base_url\n",
    "print(img_dir)\n",
    "\n",
    "train_split = 'train'\n",
    "train_file = '%s/Annotations/%s.json' %(base_url, train_split)\n",
    "train_data = requests.get(train_file, allow_redirects=True)\n",
    "print(train_file)\n",
    "\n",
    "test_split = 'test'\n",
    "test_file = '%s/Annotations/%s.json' %(base_url, test_split)\n",
    "test_data = requests.get(test_file, allow_redirects=True)\n",
    "print(test_file)\n",
    "\n",
    "val_split = 'val'\n",
    "val_file = '%s/Annotations/%s.json' %(base_url, val_split)\n",
    "val_data = requests.get(val_file, allow_redirects=True)\n",
    "print(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 20000\n",
      "Length of test data: 8000\n",
      "Length of validation data: 3173\n"
     ]
    }
   ],
   "source": [
    "# Read the local file\n",
    "training_data = train_data.json()\n",
    "testing_data = test_data.json()\n",
    "validation_data = val_data.json()\n",
    "print(\"Length of training data:\", len(training_data))\n",
    "print(\"Length of test data:\", len(testing_data))\n",
    "print(\"Length of validation data:\", len(validation_data))\n",
    "\n",
    "image_name_train = []\n",
    "question_train = []\n",
    "label_train = []\n",
    "\n",
    "image_name_val = []\n",
    "question_val = []\n",
    "label_val = []\n",
    "\n",
    "image_name_test = []\n",
    "question_test = []\n",
    "label_test = []\n",
    "\n",
    "num_train_VQs = 20000\n",
    "for vq in training_data[0:num_train_VQs]:\n",
    "    image_name_train.append(vq['image'])\n",
    "    question_train.append(vq['question'])\n",
    "    label_train.append(vq['answerable'])\n",
    "    \n",
    "num_val_VQs = 8000\n",
    "for vq in validation_data[0:num_val_VQs]:\n",
    "    image_name_val.append(vq['image'])\n",
    "    question_val.append(vq['question'])\n",
    "    label_val.append(vq['answerable'])\n",
    "    \n",
    "num_test_VQs = 3173\n",
    "for vq in testing_data[0:num_test_VQs]:\n",
    "    image_name_test.append(vq['image'])\n",
    "    question_test.append(vq['question'])\n",
    "#     label_test.append(vq['answerable'])\n",
    "\n",
    "import pandas as pd\n",
    "image_name_train = pd.DataFrame(image_name_train, columns=['image'])\n",
    "image_name_val = pd.DataFrame(image_name_val, columns=['image'])\n",
    "image_name_test = pd.DataFrame(image_name_test, columns=['image'])\n",
    "question_train = pd.DataFrame(question_train, columns=['question'])\n",
    "question_val = pd.DataFrame(question_val, columns=['question'])\n",
    "question_test = pd.DataFrame(question_test, columns=['question'])\n",
    "\n",
    "X_train = pd.concat([image_name_train, question_train], axis=1)\n",
    "y_train = pd.DataFrame(label_train, columns=['label'])\n",
    "X_val = pd.concat([image_name_val, question_val], axis=1)\n",
    "y_val = pd.DataFrame(label_val, columns=['label'])\n",
    "X_test = pd.concat([image_name_test, question_test], axis=1)\n",
    "# y_test = pd.DataFrame(label_test, columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# Use Microsoft Azure API to extract image-based features\n",
    "subscription_key_vision = '412bc41b5b5844febf4d7cd63510fb4f'\n",
    "vision_base_url = 'https://westcentralus.api.cognitive.microsoft.com/vision/v1.0'\n",
    "vision_analyze_url = vision_base_url + '/analyze?'\n",
    "from time import sleep\n",
    "\n",
    "def analyze_image(image_url):\n",
    "    # Microsoft API headers, params, etc\n",
    "    headers = {'Ocp-Apim-Subscription-key': subscription_key_vision}\n",
    "    params = {'visualfeatures': 'Description, Tags'}\n",
    "    data = {'url': image_url}\n",
    "    # send request, get API response\n",
    "    try:\n",
    "        response = requests.post(vision_analyze_url,headers = headers,params=params,json=data)\n",
    "    except:\n",
    "        sleep(10)\n",
    "        response = requests.post(vision_analyze_url,headers = headers,params=params,json=data)\n",
    "#     response = requests.post(vision_analyze_url, headers=headers, params=params, json=data)\n",
    "    if (response.status_code == 200):\n",
    "        analysis = response.json()\n",
    "    else:\n",
    "        print(\"get image {} failed\".format(image_url))\n",
    "        analysis = {\"description\":{\"tags\":[]}}\n",
    "    return analysis\n",
    "\n",
    "def extract_features(data):\n",
    "    return {\n",
    "        'tags': data['description']['tags'],\n",
    "#         'confidence': data['tags'][0]['confidence']\n",
    "    }\n",
    "\n",
    "image_feature = {}\n",
    "def get_image_feature(X):\n",
    "\n",
    "    for i in range(100, 200):\n",
    "        image_url = img_dir + '%s' %(X['image'][i])\n",
    "        data = extract_features(analyze_image(image_url))\n",
    "        tag_i = []\n",
    "        for item in data['tags']:\n",
    "            tag_i.append(item)\n",
    "        tag_i_join = ' '.join(tag_i)\n",
    "#         image_feature.append(tag_i_join)\n",
    "        image_feature[str(i)] = tag_i_join\n",
    "        if (i%500==0):\n",
    "            print('get number',str(i))\n",
    "            \n",
    "    return image_feature\n",
    "image_feature = get_image_feature(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write image feature to csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "data = pd.DataFrame()\n",
    "indexlist = []\n",
    "featurelist = []\n",
    "for index,feature in image_feature.items():\n",
    "    indexlist.append(index)\n",
    "    featurelist.append(feature)\n",
    "data[\"id\"] = indexlist\n",
    "data[\"image_feature\"] = featurelist\n",
    "data.columns = [\"id\", \"image_feature\"]\n",
    "data.head()\n",
    "data.to_csv('image_feature_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not get 0\n",
      "get number 0\n",
      "not get 1\n",
      "not get 2\n",
      "not get 3\n",
      "not get 4\n",
      "not get 5\n",
      "not get 6\n",
      "not get 7\n",
      "not get 8\n",
      "not get 9\n",
      "not get 10\n",
      "not get 11\n",
      "not get 12\n",
      "not get 13\n",
      "not get 14\n",
      "not get 15\n",
      "not get 16\n",
      "not get 17\n",
      "not get 18\n",
      "not get 19\n"
     ]
    }
   ],
   "source": [
    "# Extract text features using Microsoft Azure\n",
    "from time import sleep\n",
    "subscription_key_text = 'e25225c679e74f61a2ab61924b41a866'\n",
    "text_analytics_base_url = 'https://centralus.api.cognitive.microsoft.com/text/analytics/v2.0/'\n",
    "key_phrase_api_url = text_analytics_base_url + 'keyPhrases'\n",
    "question_feature = {}\n",
    "def get_question_feature(question_train):\n",
    "    \n",
    "    for i in range(100, 200):\n",
    "        \n",
    "        question_json = question_train['question'][i]\n",
    "        documents = {'documents': [{'id': i, 'text': question_json}]}\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": subscription_key_text}\n",
    "        maxiter = 10\n",
    "\n",
    "        try:\n",
    "            response = requests.post(key_phrase_api_url,headers = headers,json=documents)\n",
    "        except:\n",
    "            sleep(10)\n",
    "            response = requests.post(key_phrase_api_url,headers = headers,json=documents)\n",
    "        if(response.status_code == 200):\n",
    "            question_json = response.json()['documents']\n",
    "            question = pd.DataFrame(question_json)['keyPhrases']\n",
    "            question = question.tolist()[0]\n",
    "            tag_i=[]\n",
    "            for item in question:\n",
    "                tag_i.append(item)\n",
    "            question = ' '.join(tag_i)\n",
    "            question_feature[str(i)] = question\n",
    "        else:\n",
    "            print(\"not get\",str(i))\n",
    "            question_feature[str(i)] = \"\"\n",
    "        if (i%500==0):\n",
    "            print('get number',str(i))\n",
    "            \n",
    "    return question_feature\n",
    "question_feature = get_question_feature(X_test)\n",
    "#print(question_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write key phrase to csv file\n",
    "data = pd.DataFrame()\n",
    "indexlist = []\n",
    "keywordlist = []\n",
    "for index,keyword in question_feature.items():\n",
    "    indexlist.append(index)\n",
    "    keywordlist.append(keyword)\n",
    "data[\"id\"] = indexlist\n",
    "data[\"question_keyword\"] = keywordlist\n",
    "data.columns = [\"id\", \"question_keyword\"]\n",
    "data.head()\n",
    "data.to_csv('question_feature_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
